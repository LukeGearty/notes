<html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>Inside the Machine</title><style>
/* cspell:disable-file */
/* webkit printing magic: print all background colors */
html {
	-webkit-print-color-adjust: exact;
}
* {
	box-sizing: border-box;
	-webkit-print-color-adjust: exact;
}

html,
body {
	margin: 0;
	padding: 0;
}
@media only screen {
	body {
		margin: 2em auto;
		max-width: 900px;
		color: rgb(55, 53, 47);
	}
}

body {
	line-height: 1.5;
	white-space: pre-wrap;
}

a,
a.visited {
	color: inherit;
	text-decoration: underline;
}

.pdf-relative-link-path {
	font-size: 80%;
	color: #444;
}

h1,
h2,
h3 {
	letter-spacing: -0.01em;
	line-height: 1.2;
	font-weight: 600;
	margin-bottom: 0;
}

.page-title {
	font-size: 2.5rem;
	font-weight: 700;
	margin-top: 0;
	margin-bottom: 0.75em;
}

h1 {
	font-size: 1.875rem;
	margin-top: 1.875rem;
}

h2 {
	font-size: 1.5rem;
	margin-top: 1.5rem;
}

h3 {
	font-size: 1.25rem;
	margin-top: 1.25rem;
}

.source {
	border: 1px solid #ddd;
	border-radius: 3px;
	padding: 1.5em;
	word-break: break-all;
}

.callout {
	border-radius: 3px;
	padding: 1rem;
}

figure {
	margin: 1.25em 0;
	page-break-inside: avoid;
}

figcaption {
	opacity: 0.5;
	font-size: 85%;
	margin-top: 0.5em;
}

mark {
	background-color: transparent;
}

.indented {
	padding-left: 1.5em;
}

hr {
	background: transparent;
	display: block;
	width: 100%;
	height: 1px;
	visibility: visible;
	border: none;
	border-bottom: 1px solid rgba(55, 53, 47, 0.09);
}

img {
	max-width: 100%;
}

@media only print {
	img {
		max-height: 100vh;
		object-fit: contain;
	}
}

@page {
	margin: 1in;
}

.collection-content {
	font-size: 0.875rem;
}

.column-list {
	display: flex;
	justify-content: space-between;
}

.column {
	padding: 0 1em;
}

.column:first-child {
	padding-left: 0;
}

.column:last-child {
	padding-right: 0;
}

.table_of_contents-item {
	display: block;
	font-size: 0.875rem;
	line-height: 1.3;
	padding: 0.125rem;
}

.table_of_contents-indent-1 {
	margin-left: 1.5rem;
}

.table_of_contents-indent-2 {
	margin-left: 3rem;
}

.table_of_contents-indent-3 {
	margin-left: 4.5rem;
}

.table_of_contents-link {
	text-decoration: none;
	opacity: 0.7;
	border-bottom: 1px solid rgba(55, 53, 47, 0.18);
}

table,
th,
td {
	border: 1px solid rgba(55, 53, 47, 0.09);
	border-collapse: collapse;
}

table {
	border-left: none;
	border-right: none;
}

th,
td {
	font-weight: normal;
	padding: 0.25em 0.5em;
	line-height: 1.5;
	min-height: 1.5em;
	text-align: left;
}

th {
	color: rgba(55, 53, 47, 0.6);
}

ol,
ul {
	margin: 0;
	margin-block-start: 0.6em;
	margin-block-end: 0.6em;
}

li > ol:first-child,
li > ul:first-child {
	margin-block-start: 0.6em;
}

ul > li {
	list-style: disc;
}

ul.to-do-list {
	padding-inline-start: 0;
}

ul.to-do-list > li {
	list-style: none;
}

.to-do-children-checked {
	text-decoration: line-through;
	opacity: 0.375;
}

ul.toggle > li {
	list-style: none;
}

ul {
	padding-inline-start: 1.7em;
}

ul > li {
	padding-left: 0.1em;
}

ol {
	padding-inline-start: 1.6em;
}

ol > li {
	padding-left: 0.2em;
}

.mono ol {
	padding-inline-start: 2em;
}

.mono ol > li {
	text-indent: -0.4em;
}

.toggle {
	padding-inline-start: 0em;
	list-style-type: none;
}

/* Indent toggle children */
.toggle > li > details {
	padding-left: 1.7em;
}

.toggle > li > details > summary {
	margin-left: -1.1em;
}

.selected-value {
	display: inline-block;
	padding: 0 0.5em;
	background: rgba(206, 205, 202, 0.5);
	border-radius: 3px;
	margin-right: 0.5em;
	margin-top: 0.3em;
	margin-bottom: 0.3em;
	white-space: nowrap;
}

.collection-title {
	display: inline-block;
	margin-right: 1em;
}

.page-description {
	margin-bottom: 2em;
}

.simple-table {
	margin-top: 1em;
	font-size: 0.875rem;
	empty-cells: show;
}
.simple-table td {
	height: 29px;
	min-width: 120px;
}

.simple-table th {
	height: 29px;
	min-width: 120px;
}

.simple-table-header-color {
	background: rgb(247, 246, 243);
	color: black;
}
.simple-table-header {
	font-weight: 500;
}

time {
	opacity: 0.5;
}

.icon {
	display: inline-block;
	max-width: 1.2em;
	max-height: 1.2em;
	text-decoration: none;
	vertical-align: text-bottom;
	margin-right: 0.5em;
}

img.icon {
	border-radius: 3px;
}

.user-icon {
	width: 1.5em;
	height: 1.5em;
	border-radius: 100%;
	margin-right: 0.5rem;
}

.user-icon-inner {
	font-size: 0.8em;
}

.text-icon {
	border: 1px solid #000;
	text-align: center;
}

.page-cover-image {
	display: block;
	object-fit: cover;
	width: 100%;
	max-height: 30vh;
}

.page-header-icon {
	font-size: 3rem;
	margin-bottom: 1rem;
}

.page-header-icon-with-cover {
	margin-top: -0.72em;
	margin-left: 0.07em;
}

.page-header-icon img {
	border-radius: 3px;
}

.link-to-page {
	margin: 1em 0;
	padding: 0;
	border: none;
	font-weight: 500;
}

p > .user {
	opacity: 0.5;
}

td > .user,
td > time {
	white-space: nowrap;
}

input[type="checkbox"] {
	transform: scale(1.5);
	margin-right: 0.6em;
	vertical-align: middle;
}

p {
	margin-top: 0.5em;
	margin-bottom: 0.5em;
}

.image {
	border: none;
	margin: 1.5em 0;
	padding: 0;
	border-radius: 0;
	text-align: center;
}

.code,
code {
	background: rgba(135, 131, 120, 0.15);
	border-radius: 3px;
	padding: 0.2em 0.4em;
	border-radius: 3px;
	font-size: 85%;
	tab-size: 2;
}

code {
	color: #eb5757;
}

.code {
	padding: 1.5em 1em;
}

.code-wrap {
	white-space: pre-wrap;
	word-break: break-all;
}

.code > code {
	background: none;
	padding: 0;
	font-size: 100%;
	color: inherit;
}

blockquote {
	font-size: 1.25em;
	margin: 1em 0;
	padding-left: 1em;
	border-left: 3px solid rgb(55, 53, 47);
}

.bookmark {
	text-decoration: none;
	max-height: 8em;
	padding: 0;
	display: flex;
	width: 100%;
	align-items: stretch;
}

.bookmark-title {
	font-size: 0.85em;
	overflow: hidden;
	text-overflow: ellipsis;
	height: 1.75em;
	white-space: nowrap;
}

.bookmark-text {
	display: flex;
	flex-direction: column;
}

.bookmark-info {
	flex: 4 1 180px;
	padding: 12px 14px 14px;
	display: flex;
	flex-direction: column;
	justify-content: space-between;
}

.bookmark-image {
	width: 33%;
	flex: 1 1 180px;
	display: block;
	position: relative;
	object-fit: cover;
	border-radius: 1px;
}

.bookmark-description {
	color: rgba(55, 53, 47, 0.6);
	font-size: 0.75em;
	overflow: hidden;
	max-height: 4.5em;
	word-break: break-word;
}

.bookmark-href {
	font-size: 0.75em;
	margin-top: 0.25em;
}

.sans { font-family: ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol"; }
.code { font-family: "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace; }
.serif { font-family: Lyon-Text, Georgia, ui-serif, serif; }
.mono { font-family: iawriter-mono, Nitti, Menlo, Courier, monospace; }
.pdf .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK JP'; }
.pdf:lang(zh-CN) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK SC'; }
.pdf:lang(zh-TW) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK TC'; }
.pdf:lang(ko-KR) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK KR'; }
.pdf .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.pdf:lang(zh-CN) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.pdf:lang(zh-TW) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.pdf:lang(ko-KR) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.pdf .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK JP'; }
.pdf:lang(zh-CN) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK SC'; }
.pdf:lang(zh-TW) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK TC'; }
.pdf:lang(ko-KR) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK KR'; }
.pdf .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.pdf:lang(zh-CN) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.pdf:lang(zh-TW) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.pdf:lang(ko-KR) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.highlight-default {
	color: rgba(50, 48, 44, 1);
}
.highlight-gray {
	color: rgba(120, 119, 116, 1);
	fill: rgba(120, 119, 116, 1);
}
.highlight-brown {
	color: rgba(159, 107, 83, 1);
	fill: rgba(159, 107, 83, 1);
}
.highlight-orange {
	color: rgba(217, 115, 13, 1);
	fill: rgba(217, 115, 13, 1);
}
.highlight-yellow {
	color: rgba(203, 145, 47, 1);
	fill: rgba(203, 145, 47, 1);
}
.highlight-teal {
	color: rgba(68, 131, 97, 1);
	fill: rgba(68, 131, 97, 1);
}
.highlight-blue {
	color: rgba(51, 126, 169, 1);
	fill: rgba(51, 126, 169, 1);
}
.highlight-purple {
	color: rgba(144, 101, 176, 1);
	fill: rgba(144, 101, 176, 1);
}
.highlight-pink {
	color: rgba(193, 76, 138, 1);
	fill: rgba(193, 76, 138, 1);
}
.highlight-red {
	color: rgba(212, 76, 71, 1);
	fill: rgba(212, 76, 71, 1);
}
.highlight-default_background {
	color: rgba(50, 48, 44, 1);
}
.highlight-gray_background {
	background: rgba(248, 248, 247, 1);
}
.highlight-brown_background {
	background: rgba(244, 238, 238, 1);
}
.highlight-orange_background {
	background: rgba(251, 236, 221, 1);
}
.highlight-yellow_background {
	background: rgba(251, 243, 219, 1);
}
.highlight-teal_background {
	background: rgba(237, 243, 236, 1);
}
.highlight-blue_background {
	background: rgba(231, 243, 248, 1);
}
.highlight-purple_background {
	background: rgba(248, 243, 252, 1);
}
.highlight-pink_background {
	background: rgba(252, 241, 246, 1);
}
.highlight-red_background {
	background: rgba(253, 235, 236, 1);
}
.block-color-default {
	color: inherit;
	fill: inherit;
}
.block-color-gray {
	color: rgba(120, 119, 116, 1);
	fill: rgba(120, 119, 116, 1);
}
.block-color-brown {
	color: rgba(159, 107, 83, 1);
	fill: rgba(159, 107, 83, 1);
}
.block-color-orange {
	color: rgba(217, 115, 13, 1);
	fill: rgba(217, 115, 13, 1);
}
.block-color-yellow {
	color: rgba(203, 145, 47, 1);
	fill: rgba(203, 145, 47, 1);
}
.block-color-teal {
	color: rgba(68, 131, 97, 1);
	fill: rgba(68, 131, 97, 1);
}
.block-color-blue {
	color: rgba(51, 126, 169, 1);
	fill: rgba(51, 126, 169, 1);
}
.block-color-purple {
	color: rgba(144, 101, 176, 1);
	fill: rgba(144, 101, 176, 1);
}
.block-color-pink {
	color: rgba(193, 76, 138, 1);
	fill: rgba(193, 76, 138, 1);
}
.block-color-red {
	color: rgba(212, 76, 71, 1);
	fill: rgba(212, 76, 71, 1);
}
.block-color-default_background {
	color: inherit;
	fill: inherit;
}
.block-color-gray_background {
	background: rgba(248, 248, 247, 1);
}
.block-color-brown_background {
	background: rgba(244, 238, 238, 1);
}
.block-color-orange_background {
	background: rgba(251, 236, 221, 1);
}
.block-color-yellow_background {
	background: rgba(251, 243, 219, 1);
}
.block-color-teal_background {
	background: rgba(237, 243, 236, 1);
}
.block-color-blue_background {
	background: rgba(231, 243, 248, 1);
}
.block-color-purple_background {
	background: rgba(248, 243, 252, 1);
}
.block-color-pink_background {
	background: rgba(252, 241, 246, 1);
}
.block-color-red_background {
	background: rgba(253, 235, 236, 1);
}
.select-value-color-uiBlue { background-color: undefined; }
.select-value-color-pink { background-color: rgba(225, 136, 179, 0.27); }
.select-value-color-purple { background-color: rgba(168, 129, 197, 0.27); }
.select-value-color-green { background-color: rgba(123, 183, 129, 0.27); }
.select-value-color-gray { background-color: rgba(84, 72, 49, 0.15); }
.select-value-color-transparentGray { background-color: undefined; }
.select-value-color-translucentGray { background-color: undefined; }
.select-value-color-orange { background-color: rgba(224, 124, 57, 0.27); }
.select-value-color-brown { background-color: rgba(210, 162, 141, 0.35); }
.select-value-color-red { background-color: rgba(244, 171, 159, 0.4); }
.select-value-color-yellow { background-color: rgba(236, 191, 66, 0.39); }
.select-value-color-blue { background-color: rgba(93, 165, 206, 0.27); }
.select-value-color-pageGlass { background-color: undefined; }
.select-value-color-washGlass { background-color: undefined; }

.checkbox {
	display: inline-flex;
	vertical-align: text-bottom;
	width: 16;
	height: 16;
	background-size: 16px;
	margin-left: 2px;
	margin-right: 5px;
}

.checkbox-on {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20width%3D%2216%22%20height%3D%2216%22%20fill%3D%22%2358A9D7%22%2F%3E%0A%3Cpath%20d%3D%22M6.71429%2012.2852L14%204.9995L12.7143%203.71436L6.71429%209.71378L3.28571%206.2831L2%207.57092L6.71429%2012.2852Z%22%20fill%3D%22white%22%2F%3E%0A%3C%2Fsvg%3E");
}

.checkbox-off {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20x%3D%220.75%22%20y%3D%220.75%22%20width%3D%2214.5%22%20height%3D%2214.5%22%20fill%3D%22white%22%20stroke%3D%22%2336352F%22%20stroke-width%3D%221.5%22%2F%3E%0A%3C%2Fsvg%3E");
}
	
</style></head><body><article id="1a47aacb-2d23-800a-86b8-c4bc2c0dfcc8" class="page sans"><header><h1 class="page-title">Inside the Machine</h1><p class="page-description"></p></header><div class="page-body"><h1 id="1a47aacb-2d23-80e5-a851-cdf570e43520" class="">Chapter One</h1><p id="1a47aacb-2d23-8091-a797-ef292d8a861d" class="">The heart of the modern computer is the CPU - the microprocessor</p><p id="1a47aacb-2d23-8021-a650-cbdafa1f2ff4" class="">It is a small version of the kind of circuitry that is seen when opening a television remote or old radio - a network of gates and channels</p><h2 id="1a47aacb-2d23-809c-a76e-fbbc03590b2d" class="">The calculator Model of Computing</h2><p id="1a47aacb-2d23-8048-a6f8-c710e0815c89" class="">An abstraction of computers - a computer takes a stream of instructions and a stream of data as input, and produces a stream of output. </p><h2 id="1a47aacb-2d23-80de-b52a-e0655330a168" class="">The File-Clerk Model of Computing</h2><p id="1a47aacb-2d23-8040-a62e-d19ea3e249ba" class="">“A computer is a device that shuffles nubmers around from place to place, reading, writing, erasing, and rewriting different numbers in different locations according to a set of inputs, a fixed set of rules for processing those inputs, and the prior history of all the inputs that the computer has seen since it was last reset, until a predefined set of criteria are met that cause the computer to halt”.</p><p id="1a47aacb-2d23-80b4-88c4-eab027141e1d" class="">The computer accesses a large store of sequentially arranged numbers for the purpose of altering that store to achieve a desired result. </p><p id="1a47aacb-2d23-801a-a618-c129ea69f1df" class="">Three functions - read, write, modify</p><h2 id="1a47aacb-2d23-80ce-b858-eb11d834c5b2" class="">The Stored-Program Computer</h2><p id="1a47aacb-2d23-80ea-ad7b-c4af0b09a2e6" class="">Storage - if a computer reads and writes numbers, there must be a place it reads from and writes to </p><p id="1a47aacb-2d23-809d-91a0-fce42ddc3fe7" class=""><strong>Arithmetic Logic Unit: </strong>If a computer modifies numbers, something must do the modifying — that is the ALU. </p><p id="1a47aacb-2d23-8077-bde3-e2e62ede0f82" class=""><strong>Bus: </strong>Something must move numbers between the ALU and storage - that is the Bus, a network of transmission lines for shuttiling numbers around inside the computer.</p><h2 id="1a47aacb-2d23-807c-b27b-db02193031af" class="">Refining the File-Clerk Model</h2><p id="1a47aacb-2d23-8008-b95f-d6663081bd0d" class="">Computers are fed a sequence of instructions one by one, and in order to execute them, the computer must first obtain the necessary data, then perform the calculation specified by the instruction, and finally write the result back into a place where the end user can find it. </p><p id="1a47aacb-2d23-80ca-8934-d5bd7377cc2b" class="">A computer is like a file clerk who sits at his desk all day waiting for messages from his boss. Eventually, the boss sends him a message telling him to perform a calculation on a pair of numbers. The message tells him which calculations to perform, and where in his personal filing cabinet the necessary numbers are located. The clerk retrieves the numbers from his filing cabinet, performs the calculations, and places the result back into the filing cabinet.</p><h2 id="1a47aacb-2d23-804c-a322-c8461b2590a9" class="">The Register File</h2><p id="1a47aacb-2d23-80bd-a83f-f6d4b2e2de7d" class="">We want to place the data storage as close to the ALU as possible. CPU’s limited surface area limits the size of the storage area. Most computers have a relatively small number of very fast data storage locations attached to the ALU.</p><p id="1a47aacb-2d23-8089-9e29-ee3ff3f45430" class="">These are called registers. The first x86 computers only had 8. They are arrayed in a storage structure called a register file.</p><h2 id="1a47aacb-2d23-8055-8475-d5e2911c0ea6" class="">RAM</h2><p id="1a47aacb-2d23-800a-8e09-cf4654d12dad" class="">Registers aren’t enough storage - Main Memory (in modern computers is called RAM) can provide more storage. RAM stores the data set on which the computer operates, and only a small portion of that data set at a time is moved to the registers for easy access from the ALU.</p><p id="1a47aacb-2d23-802b-9822-e1d1de89d106" class="">Main Memory is situatied a bit farther than registers. </p><p id="1a47aacb-2d23-8075-a87c-f806068ec0e5" class="">Registers and ALU are internal to the microprocessor, but Main Memory is connected to the processor via the memory bus. </p><h2 id="1a47aacb-2d23-808d-98e8-f62337a2a216" class="">Further Refining the File-Clerk Model</h2><p id="1a47aacb-2d23-802a-bb82-e5433f6f2e9d" class="">The office secretary locates files in another room the clerk doesn’t know about and brings them to the clerk.</p><h2 id="1a47aacb-2d23-8092-8f88-f38623cdf922" class="">An Example: Adding Two Numbers</h2><p id="1a47aacb-2d23-8020-937d-db74ed5c91dc" class="">To add two numbers:</p><p id="1a47aacb-2d23-808c-a5bc-f8e881b52bee" class="">The computer must first load the two operands from main memory into two source registers</p><p id="1a47aacb-2d23-8096-a2ef-e96836746c2e" class="">Add the contents of the source register and place the results in the destination register, using the ALU</p><p id="1a47aacb-2d23-80ef-8a32-f6b887b3432c" class="">Store the contents of the destination register in main memory</p><h2 id="1a47aacb-2d23-8078-bb7d-de8a08da1431" class="">A Closer Look at the Code Stream: The Program</h2><p id="1a47aacb-2d23-8027-bc13-fdc9b1bd9543" class="">Code Stream - ordered sequence of instructions</p><h3 id="1a47aacb-2d23-80af-a7c9-d6c6359e708c" class="">General Instruction Types</h3><p id="1a47aacb-2d23-80ab-8d0b-c1cef2f74513" class="">Instructions are grouped into ordered list that when grouped together tell the different parts of the computer how to work together to perform a specific task. These are called programs. </p><p id="1a47aacb-2d23-8066-9474-d7633d396f01" class="">If a programmer wants to add two numbers that are located in main meory and then store the result back in main memory, he or she must write a list of instructions to tell the computer exactly what to do. The program must consist of a load instruction (move the two numbers into registers) add, and store instructions.</p><p id="1a47aacb-2d23-802c-a8b7-c12f5fa670d6" class=""><strong>Arithmetic Instructions - </strong>tell the ALU to perform an arithmetic calculation</p><p id="1a47aacb-2d23-8090-919e-df59aec19285" class=""><strong>Memory-access Instructions </strong>- tell the parts of the processor that deal with main memory to move data from and to main memory</p><h2 id="1a47aacb-2d23-80ff-8c0e-d43890cfc1e4" class="">The DLW-1</h2><p id="1a47aacb-2d23-803f-bc14-cbd014fac65b" class="">A hypothetical computer.</p><p id="1a47aacb-2d23-803d-bf53-c2cd4967b69c" class="">Microprocessor has an ALU, four registers named A, B, C, and D. Atached to a bank of main memory that’s laid out as a line of 256 memory cells #0 to #255. </p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="1a47aacb-2d23-8079-8e1d-e46d48c2c2b1" class="code"><code class="language-C">add A, B, C</code></pre><p id="1a47aacb-2d23-80ad-b7a4-e8edae9887b2" class="">Assume the main memory looks like this:</p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="1a47aacb-2d23-8003-936c-dd260e157ccb" class="code"><code class="language-Plain Text">	#11 #12 #13 #14
	12   6   2   3</code></pre><p id="1a47aacb-2d23-8009-bfe6-e1ef66a79def" class="">An example code would look like this:</p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="1a47aacb-2d23-8074-a645-df3f5f912e1f" class="code"><code class="language-Plain Text">load #12, A
load #13, B
add A, B, C
store C, #14</code></pre><p id="1a47aacb-2d23-80f7-85e0-f6449d77938a" class="">This code would load the contents of memory cell #12 into Register A (6), load the contents of memory cell #13 into B (2), add them together and store that in C (8), and store the results in memory Cell 14.</p><h2 id="1a47aacb-2d23-8078-9569-f326aae77f39" class="">A Closer Look at Memory Accesses: Register vs Immediate</h2><p id="1a47aacb-2d23-8012-be2c-fdf1aa18a0a4" class="">In reality there are milions of of potential memory locations in which data can be stored. You won’t always know the exact memory location of every number. Modern computers allow the contents of a register to be used as a emmory address.</p><p id="1a47aacb-2d23-8075-be32-f9cf023b7f5e" class="">Memory Addresses are just regular whole numbers specially marked with the # sign. They can be stored in registers - and stored in memory - like any other number.  So the above code can be modified (assume we wrote the number 12 into D)</p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="1a47aacb-2d23-80f9-992a-e4b090c49c7b" class="code"><code class="language-Plain Text">load #D, A
load #13, B
add A, B, C
store C, #14</code></pre><p id="1a47aacb-2d23-805b-8e0e-e2741d24247d" class="">Memory addresses can be stored in memory cells as well as in registers. </p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="1a47aacb-2d23-806b-8dfc-fa5e0774af9e" class="code"><code class="language-Plain Text">load #11, D
load #D, A
load #13, B
add A, B, C
store C, #14</code></pre><p id="1a47aacb-2d23-8097-81f8-c9b6a4dba0c6" class="">
</p><h2 id="1a47aacb-2d23-8073-8bdc-dde690b1b890" class="">Register-Relative Addressing</h2><p id="1a47aacb-2d23-8079-a9db-d5f13db71542" class="">If a programmer knows a data segment’s starting address (base address) in memory, he or she can access all other memory locations in that segment by adding an offset to the base address. This is called Register-Relative Addressing, and it is very useful for programmers.</p><p id="1a47aacb-2d23-80fa-9fbd-f58b45731c62" class="">This code would look like:</p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="1a47aacb-2d23-80a2-9a9d-db8e4410bee4" class="code"><code class="language-Plain Text">load #(D + 108), A
store B, #(D + 108)</code></pre><p id="1a47aacb-2d23-80b9-8c02-c15981e2b85a" class="">This loads the contents of location #D + 108 into register A, and writes the contents at location #D + 108 into B.</p><p id="1a47aacb-2d23-8073-8d36-e2d3704b5652" class="">This requires a quick addition operation (address calculation_ be a part of the execution of the load instruction.</p><p id="1a47aacb-2d23-80a2-b20b-f609dc8d20e8" class="">This allows programmers to write programs without knowing the exact location of data in memory. </p><p id="1a47aacb-2d23-8095-916b-f56b1492b2c2" class="">General-purpose rgisters: stores memory addresses and regular integer numbers.</p><p id="1a47aacb-2d23-8033-b025-d41558bd8b4f" class="">
</p><h1 id="1a47aacb-2d23-80d1-ba89-e57d83f78b0f" class="">Chapter Two</h1><h2 id="1a47aacb-2d23-803b-a32d-e83f6052fd45" class="">Opcodes and Machine Language</h2><p id="1a47aacb-2d23-8059-9fd4-d4633cbf0902" class="">Both memory addresses and instructions are ordinary numbers that can be stored in memory. In order for computers to run a program,the program must be rendered in binary notation.</p><h3 id="1a47aacb-2d23-80f2-b3a8-cf058e4fb1be" class="">Machine language on the DLW-1</h3><p id="1a47aacb-2d23-80f1-866c-e57cd0c04962" class="">English words like ad, load, and store are mnemonics -they’re reasy for people to remember. They’re mapped to a string of binary numbers called opcodes. </p><h3 id="1a47aacb-2d23-8055-8de8-ce8b58cc6056" class="">Binary Encoding of Arithmetic Instructions</h3><p id="1a47aacb-2d23-8034-83be-d0025cb63581" class="">In a register-type arithmetic instruction, the first bit of the instruction is the mode bit. If it is set to 0, then the instruction is a register-type instruction, if it’s set to 1, the instruction is of the immediate type (an actual number)</p><p id="1a47aacb-2d23-8034-a061-f107c67f42c3" class="">Bits 1-3 specify the opcode. Bits 4-5 specify the first source register, 6-7 the second source register, and 8-9 the destination. Bits 10-15 are 0s for padding.<br/>If they contain immediate values, the first byte is mode, opcode, source, destination, then the second byte contains the immediate value in binary.<br/></p><h3 id="1a47aacb-2d23-8097-adce-c9249d84d386" class="">Binary Encoding of Memory Access Instructions</h3><p id="1a47aacb-2d23-806f-af24-c8c9a4024139" class="">If there is an immediate-type instruction format, the soruce field is unneeded and is zeroed out.</p><p id="1a47aacb-2d23-8024-85fe-fcdbfa7c9422" class="">First byte is mode, opcode, 00, destination. Second byte is 8-bit immediate source address. </p><p id="1a47aacb-2d23-8095-8e65-f4b4b4c916ae" class="">For a register-relative addressed load, the base field will specify the register that contains the base address, and in the second byte the 8-bit immediate offset is contained.</p><h3 id="1a47aacb-2d23-806d-8fba-d33ba04e3cbe" class="">The Store Instruction</h3><p id="1a47aacb-2d23-8094-b299-df489bc3c07b" class="">Same as for load, except the destination field specifies a register containing a destination memory address, and the sourc1 field specifies the register containing the data.</p><p id="1a47aacb-2d23-809a-a268-efb57e469bf6" class="">Uses the <strong>same format</strong> as a register-relative load. Key differences: <strong>Destination field</strong>: Set to a <strong>nonzero</strong> value. <strong>Offset</strong>: Stored in the second byte of the instruction. <strong>Base address</strong>: Stored in a register (by convention, usually <strong>register D</strong>, but it could be another).</p><h3 id="1a47aacb-2d23-8022-9eaa-e4a78e0567af" class="">Translating an Example Program into Machine Language</h3><p id="1a47aacb-2d23-8054-bd71-fbfca6b57e1b" class="">Take the below code for the DLW-1</p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="1a47aacb-2d23-8039-98bc-cf0ee04e3cc5" class="code"><code class="language-Plain Text">load #12, A
load #13, B
add A, B, C
store C, #14</code></pre><p id="1a47aacb-2d23-8019-ba67-c67a792034bf" class="">Its Machine language would look something like this:</p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="1a47aacb-2d23-8071-8821-ce7f9a06e56a" class="code"><code class="language-Plain Text">10100000 00001100
10100001 00001101
00000001 10000000
10111000 00001110</code></pre><p id="1a47aacb-2d23-8051-8f54-f4fb8f70fc59" class="">Real Examples are usually longer and more complex. </p><p id="1a47aacb-2d23-8078-a1ca-dff05f293b8e" class="">Proram instructions are translated into machine language in a mechanical, predefined manner, and even in the case of a fully modern microprocessor, doing such translations by hand is merely a matter of knowing the instruction format and having access to the right charts and tables.</p><h2 id="1a47aacb-2d23-8093-beb0-e53cc79e415c" class="">The Programming Model and the ISA</h2><p id="1a47aacb-2d23-80f2-a835-ebfc6c607d4a" class="">Converting human-readable programs into machine-readable binary code - the assembly language</p><h3 id="1a57aacb-2d23-80fc-8190-e38ee3441dd9" class="">The Programming Model</h3><p id="1a57aacb-2d23-8089-9a35-c594cf0ba704" class="">The programming model is the programmer’s interface to the microprocessor. </p><h3 id="1a57aacb-2d23-80b6-b48d-e9f6c3ebcc6b" class="">The Instruction Register and Program Counter</h3><p id="1a57aacb-2d23-8063-bdda-f093375c6642" class="">Each Instruction in a program lives at its own memory address. To execute the lines of a program, the computer simply begins at the program’s starting address.</p><h3 id="1a57aacb-2d23-80a5-8fef-fa50b6f93578" class="">Instruction Fetch: Loading the Instruction Register</h3><p id="1a57aacb-2d23-80dc-938c-c6989f095199" class="">The program counter keeps track of the address of the next instruction. The instruction register is the currently executed instruction. </p><h3 id="1a57aacb-2d23-8099-af66-f430bd1c4916" class="">Running a Simple Program</h3><p id="1a57aacb-2d23-807a-8b0e-dd4ad3c8db71" class="">Fetch the next instruction from the address stored in the program counter, load that instruction in the instruction register. Increment the program counter.</p><p id="1a57aacb-2d23-8098-a949-c3308596d21d" class="">Decode the instruction in the instruction register.</p><p id="1a57aacb-2d23-80cc-a1d9-f9860db4b2f9" class="">Execute the instruction: if the instruction is arithmetic, use ALU and register file. If it is a memory access instruction, execute it using the memory-access hardware.</p><h2 id="1a57aacb-2d23-80a8-bf48-e652272d5b88" class="">The Clock</h2><p id="1a57aacb-2d23-80a8-8a3e-e964442e2703" class="">Instructions are perfomred according to the pulse of a clock that governs every action the processor takes.</p><p id="1a57aacb-2d23-80e4-a5ca-e8ccf0cb3e1f" class="">Clock generator module on the mothrboard generates a clock pulse, which is like a metronome for the instructions.</p><h2 id="1a57aacb-2d23-80ea-a4e6-cd3be2b3cc93" class="">Branch Instructions</h2><p id="1a57aacb-2d23-8083-8584-d5e25eac52ee" class="">The processor moves through each line in a program. Branch Instructions can cause it to jump forward lines or back lines.</p><h3 id="1a57aacb-2d23-80d6-8ae7-eb81016c390d" class="">Unconditional Branch</h3><p id="1a57aacb-2d23-80b4-ae16-ce58327e904a" class="">The instruction is simply to jump to a target. The program counter’s address is replaced with the address in the target command. </p><h3 id="1a57aacb-2d23-8040-a2e7-e48d5a910e52" class="">Conditional Branch</h3><p id="1a57aacb-2d23-80ce-a420-c25437ca5b35" class="">The instruction will jump if certain conditions are met. </p><p id="1a57aacb-2d23-8078-8a5f-c30472354d92" class="">SPecial register must be used to store information on the result of arithmetic instructions (whether it is 0, nonzero, positive or negative, etc).</p><h3 id="1a57aacb-2d23-8088-bc79-d55bcff0c6e3" class="">Branch Instructions and the Fetch-Execute Loop</h3><p id="1a57aacb-2d23-8030-b440-e121a3dda78b" class="">Fetch next instructions from address stored in the program counter, load that instruction to instruction register, increment the program counter.</p><p id="1a57aacb-2d23-808e-860c-ef26510068d3" class="">Decode instruction in instruction register</p><p id="1a57aacb-2d23-80aa-af7e-f90bd267ddd4" class="">Execute the instruction in the instruction register:<br/>a. if the instruction is arithmetic, execute it using the ALU<br/></p><p id="1a57aacb-2d23-80af-a5dd-f538e2492d9d" class="">b. If the instruction is memory-access, execute it using the memory hardware</p><p id="1a57aacb-2d23-80cd-acc8-e008e054f3e9" class="">c. If the instruction is a branch, execute it using the control unit and program counter</p><h1 id="1a57aacb-2d23-8017-818f-f4c117cda5e3" class="">Chapter 3</h1><p id="1a67aacb-2d23-80a0-b38c-ff71d0095c83" class="">Pipelined Execution is one of the key innovations that underlies the rapid performance increases that have characterized the past few decades of microprocessor development.</p><p id="1a67aacb-2d23-80df-ac21-f1d8536156cd" class="">Pipelined Execution:  decreases the amount of time that the processor takes to execute a program, increases the speed at which the processor operates</p><h3 id="1a67aacb-2d23-80bd-97fb-cad36b9c5f20" class="">Lifeccycle of an Instruction</h3><p id="1a67aacb-2d23-80c6-804f-f4e5c28733f1" class="">The Fetch-Decode-Execute steps for an add A, B, C instruction:</p><ol type="1" id="1a67aacb-2d23-80c7-9d02-c4119722829d" class="numbered-list" start="1"><li>Fetch the next instruction from the address stored in the program<br/>counter, and load that instruction into the instruction register.<br/>Increment the program counter.<br/></li></ol><ol type="1" id="1a67aacb-2d23-80f0-89f8-d0a1bcec164d" class="numbered-list" start="2"><li>Decode the instruction in the instruction register.</li></ol><ol type="1" id="1a67aacb-2d23-80d6-93a6-f56327ee3f7e" class="numbered-list" start="3"><li>Execute the instruction in the instruction register. Because the instruc-<br/>tion is not a branch instruction but an arithmetic instruction, send it to the ALU.<br/>a. Read the contents of registers A and B.<br/>b. Add the contents of A and B.<br/></li></ol><ol type="1" id="1a67aacb-2d23-80fb-9f09-e52bb5ea9f5d" class="numbered-list" start="4"><li> Write the result back to register C.</li></ol><p id="1a67aacb-2d23-80d4-bcc1-d878799dfbe2" class="">
</p><p id="1a67aacb-2d23-803a-8527-f51f875b4e0e" class="">The four stages of a classic RISC pipeline: </p><ol type="1" id="1a67aacb-2d23-8059-b010-dcde37dc3235" class="numbered-list" start="1"><li>Fetch</li></ol><ol type="1" id="1a67aacb-2d23-80be-b657-cd07c07c588c" class="numbered-list" start="2"><li>Decode</li></ol><ol type="1" id="1a67aacb-2d23-809b-83c4-da1e62e90062" class="numbered-list" start="3"><li>Execute</li></ol><ol type="1" id="1a67aacb-2d23-809e-a9e4-ec5b9a8dc9ce" class="numbered-list" start="4"><li>Write (or write-back)</li></ol><p id="1a67aacb-2d23-80ed-823b-e92defe68b92" class="">Each can represent one phase in the lifecycle of an instruction.</p><h3 id="1a67aacb-2d23-806a-98fe-c14d72258e86" class="">Basic Instruction Flow</h3><p id="1a67aacb-2d23-80d1-8c71-e52aa330d191" class="">Front End and Back End of CPUs - The Front End is responsible for fetching and decoding, the back end is responsible for executing.  Control unit and I/O unit is in Front End, the ALU is in the Back End.</p><h3 id="1a67aacb-2d23-8020-9bd8-ff65df6ada96" class="">Pipelining Explained</h3><p id="1a67aacb-2d23-80e2-b6de-dc2df5970f0f" class="">Imagine a factory creating a car - where 1 person works on each part of the car before passing it on to the next part of the car to another person, and they sit idly until the car is complete. This would be very slow. To speed things up, when the part of the car is passed on to the next person in line, the person begins working on a new part. </p><h3 id="1a67aacb-2d23-800a-a261-cae4606cb19b" class="">A non-pipelined processor</h3><p id="1a67aacb-2d23-801c-aa9f-de1ef102cb3b" class="">Will be simple to design, but waste a lot of hardware resources. In the Fetch-Decode-Execute-Write cycle, each instruction goes through this in a single cycle. If the cycle is 4 ns, for example, each would take 1 ns. This means that the hardware that isn’t responsible for that part of the cycle will be idle.</p><h3 id="1a67aacb-2d23-8033-8f3e-f1f4ed7ca682" class="">A pipelined processor</h3><p id="1a67aacb-2d23-8051-a6b9-e8244ddd55fb" class="">Breaking down its instruction lifecycle into a series of piepline stages that can be completed in sequence by specialized hardware.</p><p id="1a67aacb-2d23-80ec-9c33-e07353725e8d" class="">Kind of like an assembly line. It will take a little bit to get to the end, but once it does it’ll continuously be producing.</p><h3 id="1a67aacb-2d23-8096-a8cb-c8c5364bc9b6" class="">Shrinking the Clock</h3><p id="1a67aacb-2d23-80bb-abba-d1286a1be5aa" class="">In a pipelined processor, the clock cycle time is shrunk to match the time it takes for each stage of the fetch-decode-execute-write cycle to complete its work so that at the start of each clock cycle, the stage hands off the instruction it was working on to the next stage in the pipleine.</p><h3 id="1a67aacb-2d23-80f6-8795-c613997c2bd8" class="">Shrinking Program Execution Time</h3><p id="1a67aacb-2d23-80b0-9903-c48e462cb65d" class="">The total execution time for each individal instruction isn not changed by pipelining. If the cycle is 1 ns, it will still take 1 ns to complete an instruction. It instead speeds up program execution time (the number of nanoseconds that it takes to execute an entire program)</p><p id="1a67aacb-2d23-8058-a0c4-d25ba7694986" class="">Pipeline depth is how many stages there are. Increasing this increases the instruction throughput. The clock cycle must be adjusted to accomodate — it must become shorter.</p><h3 id="1a67aacb-2d23-804c-ad91-d19ede554b4a" class="">Program Execution Time and Completion Rate</h3><p id="1a67aacb-2d23-80c4-bff4-c980e4e31efb" class="">program exeuction time =  number of instructions in program / instruction completion rate</p><ul id="1a67aacb-2d23-8061-b4d1-c137d9e88ce7" class="bulleted-list"><li style="list-style-type:disc"><strong>Pipelining allows multiple instructions to be in progress at the same time</strong>.</li></ul><ul id="1a67aacb-2d23-80ec-9730-eb5302960780" class="bulleted-list"><li style="list-style-type:disc">Because of this, <strong>completion rate increases</strong> <strong>without reducing execution time</strong>.<ul id="1a67aacb-2d23-8057-bc7d-c7093016d6fd" class="bulleted-list"><li style="list-style-type:circle">For example, an instruction may still take <strong>4 ns</strong> to go through all stages.</li></ul><ul id="1a67aacb-2d23-80df-b7ce-e779f30c3765" class="bulleted-list"><li style="list-style-type:circle">But since multiple instructions are <strong>overlapping in different stages</strong>, the processor <strong>finishes one instruction per cycle</strong> (e.g., every 1 ns).</li></ul><ul id="1a67aacb-2d23-80a2-b968-c6f81ee2cedd" class="bulleted-list"><li style="list-style-type:circle">So even though <strong>execution time is still 4 ns</strong>, the <strong>completion rate is now 1 instruction per ns</strong>, not 0.25.</li></ul></li></ul><h3 id="1a67aacb-2d23-80e0-a14a-e0e7e0d6a85d" class="">The Relationship Between Completion Rate and Program Execution Time</h3><p id="1a67aacb-2d23-804b-9474-c9e699d506c0" class="">✅ <strong>Pipelines take time to &quot;warm up&quot;</strong> before reaching full speed.</p><p id="1a67aacb-2d23-80a8-9a02-e899b556e63e" class="">✅ <strong>In the first few cycles, the speedup is less than expected</strong> because of the initial fill-up time.</p><p id="1a67aacb-2d23-800f-b049-e0cb7a50386c" class="">✅ <strong>Over time, the real-world completion rate gets closer to the theoretical max</strong> as the pipeline stays full.</p><p id="1a67aacb-2d23-80c2-8b25-d146f40b8c91" class="">✅ <strong>For long programs, pipelining provides nearly the full expected speedup</strong> (close to 4x in this case).</p><ul id="1a67aacb-2d23-80db-ba25-e302317c5f4a" class="bulleted-list"><li style="list-style-type:disc"><strong>Theoretical completion rate</strong>: The best possible speed once the pipeline is full (<strong>1 instruction per ns</strong>).</li></ul><ul id="1a67aacb-2d23-8028-b6c5-d45d419ad83e" class="bulleted-list"><li style="list-style-type:disc"><strong>Real-world average completion rate</strong>: Slower at first but improves as more instructions are processed.<ul id="1a67aacb-2d23-800a-bffb-cfd854f17248" class="bulleted-list"><li style="list-style-type:circle">After <strong>8 ns</strong>, the pipelined processor averages <strong>0.625 instructions per ns</strong>.</li></ul><ul id="1a67aacb-2d23-8098-a03d-d8e5dea0dccc" class="bulleted-list"><li style="list-style-type:circle">After <strong>1,000 ns</strong>, it averages <strong>0.996 instructions per ns</strong>, nearly reaching the theoretical max.</li></ul></li></ul><h3 id="1a67aacb-2d23-804f-8c77-e4c742601a4e" class="">Instruction Throughput and Pipeline Stalls</h3><p id="1a67aacb-2d23-8048-8d94-fc1d32e1830c" class="">Pipelining adds some complexity to the ways in which you assess the processor’s performance</p><p id="1a67aacb-2d23-8026-98a1-cd94e52a7bcf" class=""><strong>Instruction Throughput</strong></p><p id="1a67aacb-2d23-806a-b5f7-ee5211f9d326" class="">The number of instructions that the processor completes each clock cycle. Instructions Per Clock.</p><p id="1a67aacb-2d23-8075-bdf9-fb185fa0002d" class=""><strong>Maximum theoretical instruction throughput</strong></p><p id="1a67aacb-2d23-8028-8f44-f61e4224ff4b" class="">The theoretical maximum number of instructions that the processor can finish executing on each clock cycle.</p><p id="1a67aacb-2d23-805e-a3ac-e235d7e8cdde" class=""><strong>Average Instruction throughput</strong></p><p id="1a67aacb-2d23-80e3-9e9c-eee668db8907" class="">The average number of instructions per clock (IPC) that the processor has actually completed over a certain number of cycles.</p><h3 id="1a67aacb-2d23-80a5-abef-fb3bf58ace8c" class="">Pipeline Stalls</h3><p id="1a67aacb-2d23-809b-8d7f-c768c4ce07b4" class="">Sometimes instructions stall in a pipeline. All of the instructions in the stage below the one where the stall happen continue advancing normally, and all the instructions behind it back up. </p><h3 id="1a67aacb-2d23-805d-a48c-f81f9674d7bc" class="">Instruction Latency and Pipeline Stalls</h3><p id="1a67aacb-2d23-8081-a2eb-ff8745cd3fc3" class="">Instruction Latency - the number of clock cycles it takes for the instruction to pass through the pipeline. </p><h3 id="1a67aacb-2d23-803e-aa13-e880b5b96275" class="">Limits to Pipelining</h3><p id="1a67aacb-2d23-8082-a7c8-f3fe857672be" class="">There are some practical limits to how deeply you can pipeline an assembly line or a processor before the actual speedup in completion rate that you gain from pipelining starts to become significantly less than the ideal speedup. </p><h3 id="1a67aacb-2d23-803c-84f9-e7e0d550df91" class="">Clock Period and Completion Rate</h3><p id="1a67aacb-2d23-80db-962b-ff33162390b3" class="">If the pipelined processor’s clock cycle time, or clock period, is longer than its ideal length, the processor’s completion rate will suffer. If the instruction throughput stays fixed at, one instruction/clock, then as the clock period increases, the completion rate decreases. </p><h3 id="1a67aacb-2d23-8066-aa81-f97fd757ed31" class="">The Cost of Pipelining</h3><p id="1a67aacb-2d23-8060-a46b-cbbc380a810e" class="">Pipelining requires a nontrivial amount of extra bookkeeping and buffering logic to implement, so it incurs an overhead cost in transistors and die space. </p><h1 id="1a67aacb-2d23-80d2-a108-c3b153c5a249" class="">Chapter 4</h1><p id="1a67aacb-2d23-8033-833a-e6078d9791a8" class="">The programming model is essentially a user interface for the CPU.</p><p id="1a87aacb-2d23-80cd-86cc-f1ee757ddb51" class="">In the early days, computers had separate chips for the ALU, control unit, registers, etc. These were slow.</p><p id="1a87aacb-2d23-809a-848a-dc60862060f6" class="">Then the Intel 4004 integrated all of these onto a single 2300 transistor chip. This was the world’s first microprocessor. </p><p id="1a87aacb-2d23-801b-a34d-c29d330a1a3c" class="">Then Intel 8080 came out - the first general purpose CPU.</p><p id="1a87aacb-2d23-8072-9a8c-e4d84d9a5a93" class="">Over time, more transistors could be packed onto a single chip. Desgners wanted to improve performance - they put more ALUs on there to do more instructions - superscalar.</p><p id="1a87aacb-2d23-80f1-baa5-fb0692d35351" class="">The DLW-2 - hypothetical computer - has two ALUs.</p><p id="1a87aacb-2d23-8029-a387-f0ef0798a4a9" class="">Adds a Dispatch phase to the decode phase - whether or not two instructions can be executed in parallel (on the same clock cycle)</p><p id="1a87aacb-2d23-80a0-994e-e2bf0ac131b3" class="">If the processor wants to execute multiple instructions at once, it needs to be able to fetch them at the same time. </p><p id="1a87aacb-2d23-80d3-b824-d76eae563a2d" class="">If it runs across branched instructions that jump to another part of memory, then that second instruction is discarded.</p><h2 id="1a87aacb-2d23-8076-82d1-f701211a4227" class="">Superscalar Computing and IPC</h2><p id="1a87aacb-2d23-8084-ae41-ed8a9eb2b7f3" class="">Superscalar increases the number of instructions per clock that a microprocessor completes.</p><p id="1a87aacb-2d23-80b8-a904-fb42e6689c6b" class="">The more ALu piplins that a processor has in parallel, the more instructions it can add to that box on each cycle.</p><h3 id="1a87aacb-2d23-80f9-a994-dcfd1e2b56f7" class="">Expanding Superscalar Processing with Execution Units</h3><p id="1a87aacb-2d23-8052-a3e1-f9db59e2f82d" class="">Modern processors do more with superscalar execution than just add a second ALU - They distribute the work of handling different types of instructions among different types of execution units. </p><h3 id="1a87aacb-2d23-80c8-b286-dbf863a88af8" class="">Basic Number FOrmats and Computer Arithmetic</h3><p id="1a87aacb-2d23-8077-80f2-caefe99a58fa" class="">Numbers are divided into integers (fixed-point) and floating-point numbers. </p><p id="1a87aacb-2d23-80c0-8d33-d3a90d1eae3d" class="">It’s harder for operations to be performed on floating-point numbers. </p><p id="1a87aacb-2d23-80b5-a4bc-cc110a35894d" class="">Both numbers can be dided into scalars and vectors. Scalars are values that have one numerical component. Vector is multicomponented - (like an array or sequence)</p><p id="1a87aacb-2d23-80e9-b56c-f89043d5a140" class="">There arithmetic operations like addition, subtraction, etc. Performed on any kind of number.</p><p id="1a87aacb-2d23-80d4-a132-c56cd17b7451" class="">Then there are logical (Boolean) operations like AND, OR, NOT, XOR, bit shifts, rotates. They are performed on scalar and vector integers.</p><h3 id="1a87aacb-2d23-805e-b61b-f54958fa7a1f" class="">Arithmetic Logic Units</h3><p id="1a87aacb-2d23-8086-b38f-c915996806ca" class="">Early microprocessors - all integer arithmetic and logical operations were handled by the ALU. Floating-points were performed by a companion chip, the arithmetic coprocessor. Eventually it was integrated onto the CPU as a separate execution unit alongside the ALU. </p><h3 id="1a87aacb-2d23-80b8-93a6-d235332e2047" class="">Memory-Access Units</h3><p id="1a87aacb-2d23-8098-840c-ce84cb45a100" class="">Load Store Unit (LSU) is responsible for the execution of load and store instructions as well as for address generation. </p><p id="1a87aacb-2d23-8018-8373-d77070326cd3" class="">Branch Execution Unit (BEU) is responsible for executing conditional and unconditional branch instructions. BEU of the DLW series reads the processor status word as described in Chapter 1.</p><h2 id="1a87aacb-2d23-80c3-9dea-f742af57e72c" class="">Microarchitecture and the ISA</h2><p id="1a87aacb-2d23-80f0-b5ab-f08b57a7940e" class="">The programming model is what the programmer sees when writing code. </p><p id="1a87aacb-2d23-80a8-bcb5-f0ca7e6c29c0" class="">The actual hardware implementation can be different.</p><p id="1a87aacb-2d23-8052-8fae-cfcc964219b1" class="">The ISA is the set of instructions provided by the processor. </p><p id="1a87aacb-2d23-803a-badc-fd1048507a2f" class="">The DLW-1 and DLW-2 have the same ISA - they provide the same instructions and programming model - their hardware implementation (single ALU vs two ALUs) are different. </p><p id="1a87aacb-2d23-80e9-9b6d-d2a4e2477ded" class="">Microarchitecture is the specific hardware design used to implement an ISA.</p><p id="1a87aacb-2d23-800d-a5ef-dd2ec031e178" class="">Intel’s x86 hardware became more complex while the ISA was unchanged. There are ISA extensions that extend the features to accomodate new hardware (for floating-point instructions for instance)</p><h3 id="1a87aacb-2d23-8069-9a66-f93ce7bb0e91" class="">A Brief History of the ISA</h3><p id="1a87aacb-2d23-80ad-b430-c4d3995ddfc5" class="">Back in the early days, software was like game console’s - programmers wrote it directly to the unique hardware.</p><p id="1a87aacb-2d23-8010-97af-cddae9c8830e" class="">IBM solved this with the release of the IBM System / 360, which introudced the concept of the ISA as a layer of abstraction. </p><p id="1a87aacb-2d23-808d-838f-ccafcd887e5b" class="">A microcode engine is like a CPU within a CPU that helps translate complex ISA instructions into a series of simpler internal machine instructions.</p><p id="1a87aacb-2d23-8082-b5b3-f732bc510a36" class="">This was flexible and provided backwards compatibility, but was slow and costly. </p><p id="1a87aacb-2d23-80ac-bd02-c7e997ea9eda" class="">The Reduced Instruction Set Computing (RISC) eliminated microcode -  reducd the numbr of instructions in the instruction set and reduced the sizeand complexity of each instruction.</p><h3 id="1a87aacb-2d23-80e1-9b83-dc22c5aa7105" class="">Moving Complexity from Hardware to Software</h3><p id="1a87aacb-2d23-808c-8ad2-fef9dd507709" class="">Writing in Complex Instruction Set Computing (CISC) Assembly is powerful and complex</p><p id="1a87aacb-2d23-8050-b051-f0a5a744b9f1" class="">Writing in RISC assebly is simple and few.</p><p id="1a87aacb-2d23-80ec-8c16-f4cdb7319461" class="">Programmers stopped writing in Assembly and started writing in High level languages like C.</p><h2 id="1a87aacb-2d23-80d9-af86-dd5196c993e5" class="">Challenges to Pipelining and Superscalar Design</h2><p id="1a87aacb-2d23-8098-88b4-dbca72f3e174" class="">Hazards - conditions under which two arithmetic instructions cannot be safely dispatched in parallel for execution</p><h3 id="1a87aacb-2d23-80b1-9e1b-e068ae3e8288" class="">Data Hazards</h3><p id="1a87aacb-2d23-80c9-9d1b-cf6e6ffdcad6" class="">When one instruction depends on the results of another instruction</p><p id="1a87aacb-2d23-80f5-ad63-c4c28e3ee12e" class="">Forwarding (bypassing) reduces waiting times. Instead of waiting for results to be written to a register, the processor directly forwards the result from the ALU output to the input of the second. This means the instruction in the pipeline can start earlier.</p><p id="1a87aacb-2d23-809a-b67f-e6e8422f0d14" class="">Register renaming overcomes hazards on superscalar machines. There are many more physical registers available than the ISA defines. Theprogrammer thinks they use a smaller amount, the processor remaps original architectural registers to hidden physical registers.</p><h3 id="1a87aacb-2d23-80a3-b97e-ea176fb1f378" class="">Structural Hazards</h3><p id="1a87aacb-2d23-8030-b4ef-cef04bbb1013" class="">The processor doesn’t have enough resources to execute both instructions at once.</p><h3 id="1a87aacb-2d23-803b-9c1b-efbe09d93b2d" class="">The Register File</h3><p id="1a87aacb-2d23-808f-90a9-cc6a7d2bab00" class="">CPU registers are grouped together into a special unit called a register file. It is a memory array, and its accessed through a special itnerface that allows the ALU to read from or write to specific registers. </p><p id="1a87aacb-2d23-8090-839a-e09c48fc1bc2" class="">The ALU accesses registers via a shared data bus through read ports (for reading data) and write ports (for writing results). To perform a <strong>three-operand instruction</strong> (e.g., <code>ADD C, A, B</code>), an ALU needs <strong>two read ports</strong> and <strong>one write port</strong>. In a <strong>two-ALU superscalar CPU</strong>, the register file must have <strong>four read ports</strong> and <strong>two write ports</strong>.</p><h3 id="1a87aacb-2d23-8082-a5d2-e6c6761f3e89" class="">Control Hazards</h3><p id="1a87aacb-2d23-801a-89ce-c7279b45b8e0" class="">Branch hazards - when the processor arrives at a conditional branch and has to decide which instruction to fetch next.</p><h1 id="1a87aacb-2d23-80e5-a3b7-c85b878fa400" class="">Chapter 5</h1><h3 id="1a97aacb-2d23-80a5-9003-c25d19f55051" class="">The Original Pentium</h3><p id="1a97aacb-2d23-80b1-b913-d0cf958e53dd" class="">Introduced in 1993, it was very modest compared to modern standards. Two integer ALUs, a floating-point ALU, along with some other units. The Pentium has a level 1 cache</p><h3 id="1a97aacb-2d23-8031-ba9a-ed9f49172bfb" class="">Caches</h3><p id="1a97aacb-2d23-803d-9348-eb3f4d92ca9f" class="">It takes a huge number of processor clock cycles to transfer code and data between main memory and the registers and execution units. This would kill most of the performance gains brought on by the increase in processor clock speeds.</p><p id="1a97aacb-2d23-8087-b914-dc174568ccef" class="">Smaller amounts of faster, more expensive memory called cache memory in between main memory and the registers.</p><p id="1a97aacb-2d23-8019-94be-dbbdcfd0532e" class="">There are multiple levels of cache between main memory and the registers. The Level 1 cache is the smallest, most expensive bit of cache. Located the closest to the processor’s back end. </p><p id="1a97aacb-2d23-80af-8618-d9eed81a2d6a" class="">L2 cache is located betwen L1 cache and main memory. L3 cache is between L2 and main memory.</p><p id="1a97aacb-2d23-8095-9955-c993d05ecd55" class="">A cache hit - when something the processor needs is in the cache. It checks each cache incremntally. </p><p id="1a97aacb-2d23-80a6-a1fe-ea92e6114129" class="">A cache miss - when it isn’t in the cache. </p><h3 id="1a97aacb-2d23-803f-9c29-d27bdeca0615" class="">The Pentium’s Pipeline</h3><p id="1a97aacb-2d23-8003-a6b9-f91e27ac7f96" class="">A superscalar processor doesn’t have just one pipeline. </p><p id="1a97aacb-2d23-80ac-8e15-d63917de2ba9" class="">Each of the pentium’s pielines shares four stages: <div class="indented"><p id="1a97aacb-2d23-80c2-b377-c6f0548ca765" class="">Fetch</p><p id="1a97aacb-2d23-80f9-a14c-e9e3402f4d9d" class="">Decode-1</p><p id="1a97aacb-2d23-80f0-ad88-db728868cf22" class="">Decode-2</p><p id="1a97aacb-2d23-80b3-847e-c2b6b5c4508f" class="">Write</p></div></p><p id="1a97aacb-2d23-80f2-8aae-eb03112d66fb" class="">A processor’s various execution units can have different pipeline depths. The integer pipeline is the shortest and is taken to be the default piplline. </p><p id="1a97aacb-2d23-80e3-86b9-d3f237ca90a7" class="">The pentium’s basic integer pipleline is five stages long:<div class="indented"><p id="1a97aacb-2d23-8039-95c7-e29587c23f36" class="">Prefetch/Fetch</p><p id="1a97aacb-2d23-8060-a72e-f0127d4c5726" class="">Decode-1</p><p id="1a97aacb-2d23-8092-8445-cb6bbb195f2c" class="">Decode-2</p><p id="1a97aacb-2d23-809e-891c-c26386b318f3" class="">Execute</p><p id="1a97aacb-2d23-8040-b58e-ff026abf3471" class="">Write-back</p></div></p><p id="1a97aacb-2d23-806d-9154-f6a3e92bb9ac" class="">The x86 ISA supports multiple complex addressing modes, whic hwere originally designed to make assembly language programmers easier but ended up making everyone’s lives more difficult.</p><h3 id="1a97aacb-2d23-80e7-969b-fbca88182679" class="">The Branch Unit and Branch Prediction</h3><p id="1a97aacb-2d23-80c4-91a7-f9a156172378" class="">The Branch Unit is on the Pentium. </p><p id="1a97aacb-2d23-80af-9224-f4f2f82114da" class="">It works closely with the instruction fetcher.</p><p id="1a97aacb-2d23-80b9-9e5a-c9d2fa9fb384" class="">It contains the branch execution unit and the brand prediction uni, and whenever the front end’s decoder encounters a conditional branch instruction, it sends it to the BU to the be executed. The BU in turn sends it off to one of the other execution unit to have the instruction’s branch condition evaluated, so that the BU can determine if the branch is taken or not. </p><p id="1a97aacb-2d23-8021-9a4e-f6bf58bb55cc" class="">If it has been, it has to get th estarting address of the next block of code to be executed. The branch target must be calculated and the front end must be told to begin fetching code at the new address.</p><ol type="1" id="1a97aacb-2d23-8015-bd7a-e149eee2b74c" class="numbered-list" start="1"><li><strong>Speculative Execution and Branch Prediction</strong><ul id="1a97aacb-2d23-8096-b1a6-e8f792c16ed2" class="bulleted-list"><li style="list-style-type:disc">Modern processors <strong>speculatively execute</strong> instructions before they are certain those instructions are needed. This speeds up execution if the speculation is correct.</li></ul><ul id="1a97aacb-2d23-8068-83a1-f08ffe2590e2" class="bulleted-list"><li style="list-style-type:disc">However, speculative instructions <strong>cannot write their results</strong> to registers until the processor confirms they are on the correct path.</li></ul><ul id="1a97aacb-2d23-80e6-a6a3-ea71b57a538d" class="bulleted-list"><li style="list-style-type:disc">If the <strong>branch predictor unit (BPU)</strong> correctly predicts a branch, execution continues smoothly. Otherwise, the incorrect instructions must be <strong>discarded</strong> (pipeline flush), causing delays.</li></ul></li></ol><ol type="1" id="1a97aacb-2d23-8050-b688-fdf7a380c2a0" class="numbered-list" start="2"><li><strong>Pipeline Flushing and Performance Impact</strong><ul id="1a97aacb-2d23-8094-85ce-ec855f0ba9e2" class="bulleted-list"><li style="list-style-type:disc">If a branch is mispredicted, all speculative instructions must be thrown away, and the processor must <strong>refetch</strong> instructions from the correct path.</li></ul><ul id="1a97aacb-2d23-80f1-be72-d46bc9b1fce1" class="bulleted-list"><li style="list-style-type:disc">This <strong>flush and refill</strong> process slows down execution because it introduces <strong>pipeline bubbles</strong> (idle cycles where no useful work happens).</li></ul></li></ol><ol type="1" id="1a97aacb-2d23-80e5-8199-fc42ef393a96" class="numbered-list" start="3"><li><strong>Types of Branch Prediction</strong><ul id="1a97aacb-2d23-8064-b787-e618b38d4f52" class="bulleted-list"><li style="list-style-type:disc"><strong>Static Prediction</strong>: Simple and fast, assumes:<ul id="1a97aacb-2d23-80d5-98b0-efd313b1b3bf" class="bulleted-list"><li style="list-style-type:circle"><strong>Backward branches (loops)</strong> are <strong>taken</strong> (loop repeats).</li></ul><ul id="1a97aacb-2d23-8018-9eb5-deff6d7f9037" class="bulleted-list"><li style="list-style-type:circle"><strong>Forward branches</strong> are <strong>not taken</strong> (execution continues sequentially).</li></ul><ul id="1a97aacb-2d23-800c-8344-e7ce2094a1fa" class="bulleted-list"><li style="list-style-type:circle">Works well for loops but fails for irregular branching patterns.</li></ul></li></ul><ul id="1a97aacb-2d23-8064-9659-ebb7252ddcaf" class="bulleted-list"><li style="list-style-type:disc"><strong>Dynamic Prediction</strong>: Uses past behavior to make more informed predictions.<ul id="1a97aacb-2d23-809b-b44d-fca79e2db941" class="bulleted-list"><li style="list-style-type:circle">Uses two key structures:<ul id="1a97aacb-2d23-8011-89b2-e95be72880c0" class="bulleted-list"><li style="list-style-type:square"><strong>Branch History Table (BHT)</strong>: Stores past branch outcomes to predict future behavior.</li></ul><ul id="1a97aacb-2d23-8015-883f-c85426992db8" class="bulleted-list"><li style="list-style-type:square"><strong>Branch Target Buffer (BTB)</strong>: Stores branch targets (where to jump if the branch is taken).</li></ul></li></ul><ul id="1a97aacb-2d23-80eb-8183-dfdf82a1c30c" class="bulleted-list"><li style="list-style-type:circle">If a branch has been seen before, the BPU checks the BHT to decide if it should speculatively execute it.</li></ul></li></ul></li></ol><ol type="1" id="1a97aacb-2d23-8017-95b6-f5c318856dfc" class="numbered-list" start="4"><li><strong>Pentium’s Approach</strong><ul id="1a97aacb-2d23-80a9-b8bc-c97d4b9debd0" class="bulleted-list"><li style="list-style-type:disc">Uses <strong>both static and dynamic prediction</strong>.</li></ul><ul id="1a97aacb-2d23-8098-af28-eeef807d16a7" class="bulleted-list"><li style="list-style-type:disc">If a branch is <strong>not in the BHT</strong>, it falls back to <strong>static prediction</strong>.</li></ul><ul id="1a97aacb-2d23-803e-aa7c-e7e9bac7e6ad" class="bulleted-list"><li style="list-style-type:disc">The BHT in the Pentium has <strong>256 entries</strong>, so it cannot track all branches but still achieves a <strong>75-85% prediction success rate</strong>.</li></ul><ul id="1a97aacb-2d23-80bb-88e2-e2419730dfa2" class="bulleted-list"><li style="list-style-type:disc">Intel often refers to the <strong>BTB and BHT as a single unit</strong> (Front-End BTB).</li></ul></li></ol><h3 id="1a97aacb-2d23-805b-8a3b-efc19862c88a" class="">The Pentium’s Back End</h3><p id="1ae7aacb-2d23-8005-8af1-df3df5fb02fd" class="">The Pentium has two five-stage integer pipelines, which Intel has designated U and V, and one six-stage floating-point pipeline.</p><h3 id="1ae7aacb-2d23-80b6-bb00-fc30b455043e" class="">The Integer ALUs</h3><p id="1ae7aacb-2d23-809e-8831-e11425e26369" class="">The U and V are not fully symmetric and aren’t fully independent. </p><p id="1ae7aacb-2d23-8013-9076-d7010a015552" class="">The Pentium processor has two integer execution units, U and V, which are not fully symmetric. The U pipe is more capable, containing a shifter that the V pipe lacks. Due to this asymmetry, the U pipe is referred to as the simple integer unit (SIU) and the V pipe as the complex integer unit (CIU). Most processor designs follow a similar pattern, where one integer unit is more complex than the other. Additionally, the Pentium’s integer units are not fully independent, with restrictions on which instructions can execute in parallel. Despite these limitations, the dual integer units provided strong performance for integer-heavy applications of its time. They also play a significant role in address calculations.</p><h3 id="1ae7aacb-2d23-80fc-891a-febf1f873a95" class="">The Floating-Point ALU</h3><p id="1ae7aacb-2d23-8014-b469-e9768c2deee9" class="">Floating-point operations are more complex than integer operations, leading to longer pipelines. The Pentium follows this trend with a six-stage floating-point pipeline. Its floating-point performance is limited by two factors: (1) it can only dispatch floating-point and integer operations together under restrictive conditions, though this is not a major issue since such operations are rarely mixed, and (2) the x87 floating-point architecture, which uses a stack-based register file instead of a flat register file like RISC processors.</p><p id="1ae7aacb-2d23-806f-82a9-dc0d407ef2a1" class="">The x87 register file consists of eight 80-bit registers arranged in a stack. Data is pushed onto the stack and popped off when needed, with the topmost element (ST) being the only directly accessible value. This structure follows a FILO (first in, last out) approach, unlike a FIFO (first in, first out) queue. The stack-based design complicates data access and modifications, as elements must be removed sequentially to reach older values.</p></div></article><span class="sans" style="font-size:14px;padding-top:2em"></span></body></html>